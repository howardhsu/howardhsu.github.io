{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"[ Google Scholar ] [ GitHub ] [ Linkedin ] [ Twitter ] [ Medium ] Short Bio I am a research scientist at Facebook AI Research (FAIR) . My research interests are about multi-modal pre-training (CLIP and unCLIP), self-supervised Learning and Internet-scale data curation. Previously, I received my Ph.D in computer science from University of Illinois at Chicago, advised by Prof. Philip S. Yu and Prof. Bing Liu . I got my master in microelectronics from Peking University . During my Ph.D. study I also work as a research intern at Facebook AI , Amazon AI and WeChat AI lab . I am the winner of Yelp dataset challenge . Academic research interests: Lifelong Representation Learning , Open-world Learning , Sentiment Analysis , Question Answering and Conversational AI . News I'm open to invited talks about insights in my research, feel free to reach out. Our team is looking for research interns in multi-modal pretraining , welcome to apply. [Feb. 2020] I defended my Ph.D thesis, open-sourced my Ph.D. thesis. [Sep. 2019] Ph.D proposal in lifelong representation learning for NLP. Publication 2024 Demystifying CLIP Data (MetaCLIP) Hu Xu , Saining Xie, Xiaoqing Ellen Tan, Po-Yao Huang, Russell Howes, Vasu Sharma, Shang-Wen Li, Gargi Ghosh, Luke Zettlemoyer and Christoph Feichtenhofer. [ arxiv ], [ code ] 2023 CiT: Curation in Training for Effective Vision-Language Data ICCV 2023 Hu Xu , Saining Xie, Po-Yao Huang, Licheng Yu, Russell Howes, Gargi Ghosh, Luke Zettlemoyer, Christoph Feichtenhofer. [ paper ], [ code ] DINOv2: Learning Robust Visual Features without Supervision Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu , Herv\u00e9 Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski. [ paper ], [ code ] MAViL: Masked Audio-Video Learners NeurIPS 2023 Po-Yao Huang, Vasu Sharma, Hu Xu , Chaitanya Ryali, Haoqi Fan, Yanghao Li, Shang-Wen Li, Gargi Ghosh, Jitendra Malik, Christoph Feichtenhofer. [ paper ], [ code ] Diffusion Models as Masked Autoencoders ICCV 2023 Chen Wei, Karttikeya Mangalam, Po-Yao Huang, Yanghao Li, Haoqi Fan, Hu Xu , Huiyu Wang, Cihang Xie, Alan Yuille, Christoph Feichtenhofer. [ paper ], [ website ] 2022 Adapting a Language Model While Preserving its General Knowledge EMNLP 2022 Zixuan Ke, Yijia Shao, Haowei Lin, Hu Xu , Lei Shu and Bing Liu. [ paper ], [ code ] Continual Training of Language Models for Few-Shot Learning EMNLP 2022 Zixuan Ke, Haowei Lin, Yijia Shao, Hu Xu , Lei Shu and Bing Liu. [ paper ], [ code ] Masked Autoencoders that Listen NeurIPS 2022 Po-Yao Huang, Hu Xu , Juncheng Li, Alexei Baevski, Michael Auli, Wojciech Galuba, Florian Metze, Christoph Feichtenhofer. [ paper ], [ code ] CM3: A Causal Masked Multimodal Model of the Internet Armen Aghajanyan, Bernie Huang , Candace Ross , Vladimir Karpukhin*, Hu Xu , Naman Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer. [ arxiv ] 2021 VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding EMNLP 2021 Hu Xu , Gargi Ghosh, Po-Yao Huang, Dmytro Okhonko, Armen Aghajanyan, Florian Metze, Luke Zettlemoyer, Christoph Feichtenhofer [ arxiv ], [ code ] HTLM: Hyper-text pre-training and prompting of language models Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu , Gargi Ghosh, Luke Zettlemoyer [ arxiv ] VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding ACL Findings 2021 Hu Xu , Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph Feichtenhofer, Florian Metze, Luke Zettlemoyer [ arxiv ], [ code ] Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning NeurIPS 2021 Zixuan Ke, Bing Liu, Nianzu Ma, Hu Xu and Lei Shu [ code ] CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks EMNLP 2021 Zixuan Ke, Bing Liu, Hu Xu and Lei Shu [ code ] NUANCED: Natural Utterance Annotation for Nuanced Conversation with Estimated Distributions EMNLP Findings 2021 Zhiyu Chen, Honglei Liu, Hu Xu , Seungwhan Moon, Hao Zhou, Bing Liu [ arxiv ], [ code and data ] Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks NAACL 2021 Zixuan Ke, Hu Xu and Bing Liu [ paper ], [ code ] 2020 Understanding Pre-trained BERT for Aspect-based Sentiment Analysis COLING 2020 Hu Xu , Lei Shu, Philip S. Yu, Bing Liu [ arxiv ], [ code ] User Memory Reasoning for Conversational Recommendation COLING 2020 Hu Xu , Seungwhan Moon, Honglei Liu, Bing Liu, Pararth Shah, Bing Liu, Philip S. Yu [ arxiv ] DomBERT: Domain-oriented Language Model for Aspect-based Sentiment Analysis EMNLP Findings, 2020 Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ] Controllable Text Generation with Focused Variation EMNLP Findings, 2020 Lei Shu, Alexandros Papangelis, Yi-Chia Wang, Gokhan Tur, Hu Xu , Zhaleh Feizollahi, Bing Liu, Piero Molino [ arxiv ] 2019 Open-world Learning and Application to Product Classification The Web Conference (WWW 2019) Hu Xu , Bing Liu, Lei Shu, P. Yu [ arxiv ], [ code ] BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis (using BERT for review-based tasks) 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2019) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ paper ], [ arxiv ], [ code ], [ dataset ] Flexibly-Structured Model for Task-Oriented Dialogues SIGDIAL 2019 Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng and Gokhan Tur [paper], [code] Modeling Multi-Action Policy for Task-Oriented Dialogues 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019) Lei Shu, Hu Xu , Bing Liu and Piero Molino Review Conversational Reading Comprehension arXiv 1902.00821 Hu Xu , Bing Liu, Lei Shu and Philip S. Yu [ paper ] 2018 Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018) (This paper won Yelp Dataset Challenge Round 12 Grand Prize Award) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ paper ], [ code ], [ domain embedding ], [ bib ], [ poster ] Lifelong Domain Word Embedding via Meta-Learning International Joint Conference on Artificial Intelligence (IJCAI 2018) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ], [ code ], [ bib ], [ slides ] Dual Attention Network for Product Compatibility and Function Satisfiability Analysis AAAI Conference on Artificial Intelligence (AAAI 2018) (This paper focuses on complementary aspect extraction and polarity classification from question-answering pairs) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ], [ slides ] Incorporating the Structure of the Belief State in End-to-End Task-Oriented Dialogue Systems NeurIPS 2018 Conversational AI Workshop Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng, Gokhan Tur [ paper ] Unseen Class Discovery in Open-world Classification preprint arXiv:1801.05609 Lei Shu, Hu Xu , Bing Liu [ arxiv ] 2017 Product Function Need Recognition via Semi-supervised Attention Network IEEE International Conference on Big Data 2017 (IEEE Bigdata 2017) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ] DOC: Deep Open Classification of Text Documents 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ], [code: EMNLP2017 , www2019 ] Lifelong Learning CRF for Supervised Aspect Extraction the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ] 2016 Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion arXiv preprint arXiv:1612.04499 Hu Xu , Lei Shu, Jingyuan Zhang, Philip S. Yu [ paper ], [ dataset ], [ bib ] CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews (Previous title: Sentence-level Extraction of Complementary Entities using Large Unlabeled Product Reviews) IEEE International Conference on Big Data 2016 (IEEE Bigdata 2016) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ slides ], [ data ], [ bib ] Lifelong-RL: Lifelong Relaxation Labeling for Separating Entities and Aspects in Opinion Targets (Previous title: Separating entities and aspects in opinion targets using lifelong graph labeling) 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016) Lei Shu, Bing Liu, Hu Xu , and Annice Kim [ paper ], [ slides ], [ bib ] 2013 Planning Paths with Fewer Turns on Grid Maps AAAI Sixth Annual Symposium on Combinatorial Search Hu Xu , Lei Shu, May Huang [ paper ], [ dataset ], [ bib ] High-speed and accurate laser scan matching using classified features IEEE International Symposium on Robotic and Sensors Environments (ROSE), 2013 Lei Shu, Hu Xu , May Huang [check IEEE database], [ bib ] 2011 Accuracy analysis of power characterization and modeling Convergence and Hybrid Information Technology Springer Berlin Heidelberg Xiaolan Bai, Hu Xu and May Huang [check Springer Database] Service PC Members: ACL 2020, EMNLP 2020/2019, AACL 2020, AAAI 2020/2019, IJCAI 2018-2020, NAACL 2019, COLING 2020, WWW 2019 External Reviewer, ACL 2019, AAAI 2018, IEEE DSAA 2016 Journal Reviewer: TPAMI, JAIR, TKDD, Natural Language Engineering, IEEE Transactions on Affective Computing, Transactions on Asian and Low-Resource Language Information Processing Award Yelp Dataset Challenge Grand Prize Award AAAI Scholarship Presenter Award, University of Illinois at Chicago Travel Award, IEEE International Conference on Big Data May 4th Scholarship, Peking University Talk Google AI: Learning for Open-world, Host: Dr. Qi Li, 2019 Facebook Conversational AI Summit, Host: Dr. Alborz Geramifard 2019 Amazon Alexa AI: Learning for Open-world, Host: Dr. Young-bum Kim , 2019 AAAI 2018: Dual Attention Network for Product Compatibility and Function Satisfiability Analysis, 2018 Bigdata 2016: CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews, 2016 SoCS 2013: Planning Paths with Fewer Turns on Grid Maps, 2013","title":"Frontpage"},{"location":"#short-bio","text":"I am a research scientist at Facebook AI Research (FAIR) . My research interests are about multi-modal pre-training (CLIP and unCLIP), self-supervised Learning and Internet-scale data curation. Previously, I received my Ph.D in computer science from University of Illinois at Chicago, advised by Prof. Philip S. Yu and Prof. Bing Liu . I got my master in microelectronics from Peking University . During my Ph.D. study I also work as a research intern at Facebook AI , Amazon AI and WeChat AI lab . I am the winner of Yelp dataset challenge . Academic research interests: Lifelong Representation Learning , Open-world Learning , Sentiment Analysis , Question Answering and Conversational AI .","title":"Short Bio"},{"location":"#news","text":"I'm open to invited talks about insights in my research, feel free to reach out. Our team is looking for research interns in multi-modal pretraining , welcome to apply. [Feb. 2020] I defended my Ph.D thesis, open-sourced my Ph.D. thesis. [Sep. 2019] Ph.D proposal in lifelong representation learning for NLP.","title":"News"},{"location":"#publication","text":"","title":"Publication"},{"location":"#2024","text":"Demystifying CLIP Data (MetaCLIP) Hu Xu , Saining Xie, Xiaoqing Ellen Tan, Po-Yao Huang, Russell Howes, Vasu Sharma, Shang-Wen Li, Gargi Ghosh, Luke Zettlemoyer and Christoph Feichtenhofer. [ arxiv ], [ code ]","title":"2024"},{"location":"#2023","text":"CiT: Curation in Training for Effective Vision-Language Data ICCV 2023 Hu Xu , Saining Xie, Po-Yao Huang, Licheng Yu, Russell Howes, Gargi Ghosh, Luke Zettlemoyer, Christoph Feichtenhofer. [ paper ], [ code ] DINOv2: Learning Robust Visual Features without Supervision Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu , Herv\u00e9 Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski. [ paper ], [ code ] MAViL: Masked Audio-Video Learners NeurIPS 2023 Po-Yao Huang, Vasu Sharma, Hu Xu , Chaitanya Ryali, Haoqi Fan, Yanghao Li, Shang-Wen Li, Gargi Ghosh, Jitendra Malik, Christoph Feichtenhofer. [ paper ], [ code ] Diffusion Models as Masked Autoencoders ICCV 2023 Chen Wei, Karttikeya Mangalam, Po-Yao Huang, Yanghao Li, Haoqi Fan, Hu Xu , Huiyu Wang, Cihang Xie, Alan Yuille, Christoph Feichtenhofer. [ paper ], [ website ]","title":"2023"},{"location":"#2022","text":"Adapting a Language Model While Preserving its General Knowledge EMNLP 2022 Zixuan Ke, Yijia Shao, Haowei Lin, Hu Xu , Lei Shu and Bing Liu. [ paper ], [ code ] Continual Training of Language Models for Few-Shot Learning EMNLP 2022 Zixuan Ke, Haowei Lin, Yijia Shao, Hu Xu , Lei Shu and Bing Liu. [ paper ], [ code ] Masked Autoencoders that Listen NeurIPS 2022 Po-Yao Huang, Hu Xu , Juncheng Li, Alexei Baevski, Michael Auli, Wojciech Galuba, Florian Metze, Christoph Feichtenhofer. [ paper ], [ code ] CM3: A Causal Masked Multimodal Model of the Internet Armen Aghajanyan, Bernie Huang , Candace Ross , Vladimir Karpukhin*, Hu Xu , Naman Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer. [ arxiv ]","title":"2022"},{"location":"#2021","text":"VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding EMNLP 2021 Hu Xu , Gargi Ghosh, Po-Yao Huang, Dmytro Okhonko, Armen Aghajanyan, Florian Metze, Luke Zettlemoyer, Christoph Feichtenhofer [ arxiv ], [ code ] HTLM: Hyper-text pre-training and prompting of language models Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu , Gargi Ghosh, Luke Zettlemoyer [ arxiv ] VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding ACL Findings 2021 Hu Xu , Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph Feichtenhofer, Florian Metze, Luke Zettlemoyer [ arxiv ], [ code ] Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning NeurIPS 2021 Zixuan Ke, Bing Liu, Nianzu Ma, Hu Xu and Lei Shu [ code ] CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks EMNLP 2021 Zixuan Ke, Bing Liu, Hu Xu and Lei Shu [ code ] NUANCED: Natural Utterance Annotation for Nuanced Conversation with Estimated Distributions EMNLP Findings 2021 Zhiyu Chen, Honglei Liu, Hu Xu , Seungwhan Moon, Hao Zhou, Bing Liu [ arxiv ], [ code and data ] Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks NAACL 2021 Zixuan Ke, Hu Xu and Bing Liu [ paper ], [ code ]","title":"2021"},{"location":"#2020","text":"Understanding Pre-trained BERT for Aspect-based Sentiment Analysis COLING 2020 Hu Xu , Lei Shu, Philip S. Yu, Bing Liu [ arxiv ], [ code ] User Memory Reasoning for Conversational Recommendation COLING 2020 Hu Xu , Seungwhan Moon, Honglei Liu, Bing Liu, Pararth Shah, Bing Liu, Philip S. Yu [ arxiv ] DomBERT: Domain-oriented Language Model for Aspect-based Sentiment Analysis EMNLP Findings, 2020 Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ] Controllable Text Generation with Focused Variation EMNLP Findings, 2020 Lei Shu, Alexandros Papangelis, Yi-Chia Wang, Gokhan Tur, Hu Xu , Zhaleh Feizollahi, Bing Liu, Piero Molino [ arxiv ]","title":"2020"},{"location":"#2019","text":"Open-world Learning and Application to Product Classification The Web Conference (WWW 2019) Hu Xu , Bing Liu, Lei Shu, P. Yu [ arxiv ], [ code ] BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis (using BERT for review-based tasks) 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2019) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ paper ], [ arxiv ], [ code ], [ dataset ] Flexibly-Structured Model for Task-Oriented Dialogues SIGDIAL 2019 Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng and Gokhan Tur [paper], [code] Modeling Multi-Action Policy for Task-Oriented Dialogues 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019) Lei Shu, Hu Xu , Bing Liu and Piero Molino Review Conversational Reading Comprehension arXiv 1902.00821 Hu Xu , Bing Liu, Lei Shu and Philip S. Yu [ paper ]","title":"2019"},{"location":"#2018","text":"Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018) (This paper won Yelp Dataset Challenge Round 12 Grand Prize Award) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ paper ], [ code ], [ domain embedding ], [ bib ], [ poster ] Lifelong Domain Word Embedding via Meta-Learning International Joint Conference on Artificial Intelligence (IJCAI 2018) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ], [ code ], [ bib ], [ slides ] Dual Attention Network for Product Compatibility and Function Satisfiability Analysis AAAI Conference on Artificial Intelligence (AAAI 2018) (This paper focuses on complementary aspect extraction and polarity classification from question-answering pairs) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ], [ slides ] Incorporating the Structure of the Belief State in End-to-End Task-Oriented Dialogue Systems NeurIPS 2018 Conversational AI Workshop Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng, Gokhan Tur [ paper ] Unseen Class Discovery in Open-world Classification preprint arXiv:1801.05609 Lei Shu, Hu Xu , Bing Liu [ arxiv ]","title":"2018"},{"location":"#2017","text":"Product Function Need Recognition via Semi-supervised Attention Network IEEE International Conference on Big Data 2017 (IEEE Bigdata 2017) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ] DOC: Deep Open Classification of Text Documents 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ], [code: EMNLP2017 , www2019 ] Lifelong Learning CRF for Supervised Aspect Extraction the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ]","title":"2017"},{"location":"#2016","text":"Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion arXiv preprint arXiv:1612.04499 Hu Xu , Lei Shu, Jingyuan Zhang, Philip S. Yu [ paper ], [ dataset ], [ bib ] CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews (Previous title: Sentence-level Extraction of Complementary Entities using Large Unlabeled Product Reviews) IEEE International Conference on Big Data 2016 (IEEE Bigdata 2016) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ slides ], [ data ], [ bib ] Lifelong-RL: Lifelong Relaxation Labeling for Separating Entities and Aspects in Opinion Targets (Previous title: Separating entities and aspects in opinion targets using lifelong graph labeling) 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016) Lei Shu, Bing Liu, Hu Xu , and Annice Kim [ paper ], [ slides ], [ bib ]","title":"2016"},{"location":"#2013","text":"Planning Paths with Fewer Turns on Grid Maps AAAI Sixth Annual Symposium on Combinatorial Search Hu Xu , Lei Shu, May Huang [ paper ], [ dataset ], [ bib ] High-speed and accurate laser scan matching using classified features IEEE International Symposium on Robotic and Sensors Environments (ROSE), 2013 Lei Shu, Hu Xu , May Huang [check IEEE database], [ bib ]","title":"2013"},{"location":"#2011","text":"Accuracy analysis of power characterization and modeling Convergence and Hybrid Information Technology Springer Berlin Heidelberg Xiaolan Bai, Hu Xu and May Huang [check Springer Database]","title":"2011"},{"location":"#service","text":"PC Members: ACL 2020, EMNLP 2020/2019, AACL 2020, AAAI 2020/2019, IJCAI 2018-2020, NAACL 2019, COLING 2020, WWW 2019 External Reviewer, ACL 2019, AAAI 2018, IEEE DSAA 2016 Journal Reviewer: TPAMI, JAIR, TKDD, Natural Language Engineering, IEEE Transactions on Affective Computing, Transactions on Asian and Low-Resource Language Information Processing","title":"Service"},{"location":"#award","text":"Yelp Dataset Challenge Grand Prize Award AAAI Scholarship Presenter Award, University of Illinois at Chicago Travel Award, IEEE International Conference on Big Data May 4th Scholarship, Peking University","title":"Award"},{"location":"#talk","text":"Google AI: Learning for Open-world, Host: Dr. Qi Li, 2019 Facebook Conversational AI Summit, Host: Dr. Alborz Geramifard 2019 Amazon Alexa AI: Learning for Open-world, Host: Dr. Young-bum Kim , 2019 AAAI 2018: Dual Attention Network for Product Compatibility and Function Satisfiability Analysis, 2018 Bigdata 2016: CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews, 2016 SoCS 2013: Planning Paths with Fewer Turns on Grid Maps, 2013","title":"Talk"},{"location":"absa/","text":"Aspect-based Sentiment Analysis Although a rating can summarize a whole review, it is really the vast amount of finer details matters a lot. After all, each person's need is quite different and we wish a personalized fit of a product (or service) to our own needs. Aspect-based sentiment analysis (ABSA) aims to find fine-grained opinions from reviews. For example, in a Laptop domain, we may wish to see whether the screen , keyboard , etc. are good or not. Although there are unlimited amount of reviews with coarse-grained ratings, ABSA severely lacks supervision from humans (e.g., in the form of annotated data). The above ABSA problem can be decomposed into two important sub-tasks: aspect extraction (AE) and aspect sentiment classification (ASC). Aspect Extraction Given a review sentence, such as The retina display is beautiful. , AE aims to find aspects retina display . In DL, it is mostly formalized as a sequence labeling problem: label \"The retina display is great .\" as \"O B I O O O\" so to extract \"retina display\" as an aspect. Obviously, the context of an aspect is important and an AI agent needs to have enough domain knowledge to support such extraction, such as A beautiful thing in Laptop could be an aspect. However, counting on the strong supervision from humans aspects-by-aspects for a particular domain is impossible. We show that a simple domain word embedding can boost the performance. More ideally, a language model can boost it further as whenever you see some aspects dropped, LM really encouraging the context words to recover that aspects. This is the first paper to use BERT for AE and ASC . Aspect Sentiment Classification Given an aspect retina display and a review sentence The retina display is great. , ASC detects the polarity of that aspect positive . One challenge of ASC is to detect the polarity of opinion expressions and there could be unlimited amount of such expressions to annotate. Again language model can help this too as human tends to repeat their opinions in their writing so knowing one opinion may help to automatically understand the other. For example, in Terrible product. It could be the last thing I may consider to buy , we may infer the harder opinion of the second sentence from Terrible in the first one so to automatically learn unlimited expressions like that.","title":"Sentiment Analysis"},{"location":"absa/#aspect-based-sentiment-analysis","text":"Although a rating can summarize a whole review, it is really the vast amount of finer details matters a lot. After all, each person's need is quite different and we wish a personalized fit of a product (or service) to our own needs. Aspect-based sentiment analysis (ABSA) aims to find fine-grained opinions from reviews. For example, in a Laptop domain, we may wish to see whether the screen , keyboard , etc. are good or not. Although there are unlimited amount of reviews with coarse-grained ratings, ABSA severely lacks supervision from humans (e.g., in the form of annotated data). The above ABSA problem can be decomposed into two important sub-tasks: aspect extraction (AE) and aspect sentiment classification (ASC).","title":"Aspect-based Sentiment Analysis"},{"location":"absa/#aspect-extraction","text":"Given a review sentence, such as The retina display is beautiful. , AE aims to find aspects retina display . In DL, it is mostly formalized as a sequence labeling problem: label \"The retina display is great .\" as \"O B I O O O\" so to extract \"retina display\" as an aspect. Obviously, the context of an aspect is important and an AI agent needs to have enough domain knowledge to support such extraction, such as A beautiful thing in Laptop could be an aspect. However, counting on the strong supervision from humans aspects-by-aspects for a particular domain is impossible. We show that a simple domain word embedding can boost the performance. More ideally, a language model can boost it further as whenever you see some aspects dropped, LM really encouraging the context words to recover that aspects. This is the first paper to use BERT for AE and ASC .","title":"Aspect Extraction"},{"location":"absa/#aspect-sentiment-classification","text":"Given an aspect retina display and a review sentence The retina display is great. , ASC detects the polarity of that aspect positive . One challenge of ASC is to detect the polarity of opinion expressions and there could be unlimited amount of such expressions to annotate. Again language model can help this too as human tends to repeat their opinions in their writing so knowing one opinion may help to automatically understand the other. For example, in Terrible product. It could be the last thing I may consider to buy , we may infer the harder opinion of the second sentence from Terrible in the first one so to automatically learn unlimited expressions like that.","title":"Aspect Sentiment Classification"},{"location":"convai/","text":"Conversational AI We have the following paper for conversational AI or dialog system (more papers are under submission). Review Conversational Reading Comprehension arXiv 1902.00821 Hu Xu , Bing Liu, Lei Shu and Philip S. Yu [ paper ] Flexibly-Structured Model for Task-Oriented Dialogues SIGDIAL 2019 Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng and Gokhan Tur [paper], [code] Modeling Multi-Action Policy for Task-Oriented Dialogues 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019) Lei Shu, Hu Xu , Bing Liu and Piero Molino","title":"Conversational AI"},{"location":"convai/#conversational-ai","text":"We have the following paper for conversational AI or dialog system (more papers are under submission). Review Conversational Reading Comprehension arXiv 1902.00821 Hu Xu , Bing Liu, Lei Shu and Philip S. Yu [ paper ] Flexibly-Structured Model for Task-Oriented Dialogues SIGDIAL 2019 Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng and Gokhan Tur [paper], [code] Modeling Multi-Action Policy for Task-Oriented Dialogues 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019) Lei Shu, Hu Xu , Bing Liu and Piero Molino","title":"Conversational AI"},{"location":"dataset/","text":"Dataset (RC)^2 dataset for Review Conversational Reading Comprehension (RCRC): (RC)^2 repository Review Reading Comprehension (RRC): RRC, AE, ASC repository Complementary Entity Recognition (CER): QAs: Larger AAAI data Initial PCQA Reviews: Bigdata Pre-trained Model BERT with domain knowledge (DK): laptop , restaurant Domain word embedding: for laptop and restaurant Amazon Review Embedding Amazon Electronics Reviews QA Embedding","title":"Dataset and Resource"},{"location":"dataset/#dataset","text":"(RC)^2 dataset for Review Conversational Reading Comprehension (RCRC): (RC)^2 repository Review Reading Comprehension (RRC): RRC, AE, ASC repository Complementary Entity Recognition (CER): QAs: Larger AAAI data Initial PCQA Reviews: Bigdata","title":"Dataset"},{"location":"dataset/#pre-trained-model","text":"BERT with domain knowledge (DK): laptop , restaurant Domain word embedding: for laptop and restaurant Amazon Review Embedding Amazon Electronics Reviews QA Embedding","title":"Pre-trained Model"},{"location":"hw/","text":"Build a Deep Learning Machine under $1000 As deep learning (DL) gradually domainates the research and job markets in AI, making a deep learning machine is essential for research and practice on getting up-to-date technology. The key difference between building a PC (including a gaming PC) for programming and AI is about choosing the right GPU for DL and its corresponding components. Although there are many good articles about choosing a good GPU with quantitive analysis, or building high-end hardware system (e.g., this or this ), I feel that discovering the most cost-effective but expandable strategy of building an entry-level system could be good for the majority of researchers or AI hobbyist (that are as frugal as me). Afterall, it doesn't make sense to spend a lot of money at the begining on high-end components and quickly the price dropped a lot but you didn't have enough time to learn from the old one. In general, the most cost-effective products in the world are usually sold in large volume. So in general, you may waste a lot money on making everything on high-end level with doubled or tripled prices to compensate their low volumes of sales. Note: this article is not intended to provide an up-to-date suggestion of configuration but a general idea for a long-term and cost-effective hardware guide for entry-level AI experiment. GPU GPU could be the only part that needs a high-end one as a DL machine is a GPU-centered system. You may check this article for the GPU you want, or check how much you left after deciding the rest. We assume a single GPU setting but other components are supposed to work for 2~3 GPUs so you may add more when newer ones come out. A few important facts about GPU: First, a newer GPU may typically have double or more performance in recent years (like the boost of 10 series from 9 or 20 series with tensor cores that supports fp16, which may speed up 3~4x and reduce the consumed memory by half). So I feel it doesn't make much sense to go for multiple GPUs at the beginning just for performance. As for research or simple practice, a multi-GPU setting may introduce extra coding and make your code impossible for many other researchers to repeat if they don't have multiple ones. And maybe just after one year, a newer single GPU is always better than your 2~3 old ones with no extra coding and no slow inter-GPU communications. Second, the size of GPU memory matters a lot, where some big models may not able to run for a GPU with a small memory. This could be a big problem as it is not a performance issue that you can pay more time to run but could be totally not working (e.g., using a small batch to save memory but the training is not stable). We will discuss the rest components first so all the budget leftover can be used for your GPU, as discussed in the summary. CPU As the computation load is mostly on the GPU, a cost-effective CPU that can handle a few processes is good enough. Note that most high-end CPUs are designed for doubled or tripled cores/threads, not much for frequency (or speed) on a single process. So an ideal CPU should be on the low-end like almost free so later you can replace it with no regret. My first CPU is just a $50 pentium for a single CPU. But I suggest to use i3 (around $120) to support 2~3 GPUs (I didn't see much difference when compare them with an i5). Plus, you may get a free fan from a low-end CPU. Motherboard A good motherboard is essential for expandability. So make sure the combination of CPU/motherboard and power supply can match each other within 1~2 years of upgrades. As we aim for 2~3 GPUs in future, make sure you have 2~3 PCIe slots. PCIe should be configured at 2 * 8x for two GPUs or 2 * 8x + 4x for 3 GPUs. In most cases, one GPU runs on 8x won't hurt your performance much (compared one one 16x) but allow you to install two GPUs. PCIe 4x may throttle the performance but its OK for my NLP applications. Of course, there's no problem when you just have one GPU running at 16x and almost all motherboard can support that. I assume we may upgrade to 64GB memory in future (16GB per module), so we possibly need a motherboard with 4 memory slots. Open-box/refurbished motherboard may save a lot but still have good enough quality for 1~2 years. I have an open-boxed ASUS prime for 2 years at $80. It still works quite well now. It also comes with a (debug) power button (so I have the chance to not buy a case at all). Note that some sellers like Microcenter may have a combo with CPU to save $30, even including their open-boxed motherboard. Memory The good news is that the crazily high memory price is gone. Now you can easily pick a new 16GB memory for $75, which is usually good for 1~2 GPUs (except some poorly writen python project). SSD For the first storage device, I think no need to consider a hard disk but just go for SSD because many DL models are large and slow to load/save checkpoints. Make sure it's at least $500 GB (about $60) and 1TB could be better. Also, check if you have some external hard disks so to store not-in-use DL projects out there in future. Power Supply Consider to have a power supply to support 2~3 GPUs ahead (250w for a 1080Ti, 260w for a 2080Ti). These add up to at least 900w for 3 GPUs. I have a 850w open-boxed Corsair one with warranty for $80. Accessories To be frugal, I won't discuss things like keyboard or mouse and I assume you have at least a normally working one for those and a laptop. So after installing the OS and basic configuration. You can use your laptop to remotely run everything. Also you may consider a $30 case but I totally run my system in the air and my motherboard has a power button so no need to short-circuit the pins to power up and have a configuration that is easy to upgrade. Summary As a summary, we have a $120 CPU + $80 motherboard + $75 memory + $60 SSD + $80 power supply = $415. If I assume my budget is $1000, then I have $585 for GPU, which is good enough for a 2070 (as recommended by many articles) and close to a 2080. It depends on your budget to try 2080 Ti/Titan RTX.","title":"Build a Deep Learning Machine under $1000"},{"location":"hw/#build-a-deep-learning-machine-under-1000","text":"As deep learning (DL) gradually domainates the research and job markets in AI, making a deep learning machine is essential for research and practice on getting up-to-date technology. The key difference between building a PC (including a gaming PC) for programming and AI is about choosing the right GPU for DL and its corresponding components. Although there are many good articles about choosing a good GPU with quantitive analysis, or building high-end hardware system (e.g., this or this ), I feel that discovering the most cost-effective but expandable strategy of building an entry-level system could be good for the majority of researchers or AI hobbyist (that are as frugal as me). Afterall, it doesn't make sense to spend a lot of money at the begining on high-end components and quickly the price dropped a lot but you didn't have enough time to learn from the old one. In general, the most cost-effective products in the world are usually sold in large volume. So in general, you may waste a lot money on making everything on high-end level with doubled or tripled prices to compensate their low volumes of sales. Note: this article is not intended to provide an up-to-date suggestion of configuration but a general idea for a long-term and cost-effective hardware guide for entry-level AI experiment.","title":"Build a Deep Learning Machine under $1000"},{"location":"hw/#gpu","text":"GPU could be the only part that needs a high-end one as a DL machine is a GPU-centered system. You may check this article for the GPU you want, or check how much you left after deciding the rest. We assume a single GPU setting but other components are supposed to work for 2~3 GPUs so you may add more when newer ones come out. A few important facts about GPU: First, a newer GPU may typically have double or more performance in recent years (like the boost of 10 series from 9 or 20 series with tensor cores that supports fp16, which may speed up 3~4x and reduce the consumed memory by half). So I feel it doesn't make much sense to go for multiple GPUs at the beginning just for performance. As for research or simple practice, a multi-GPU setting may introduce extra coding and make your code impossible for many other researchers to repeat if they don't have multiple ones. And maybe just after one year, a newer single GPU is always better than your 2~3 old ones with no extra coding and no slow inter-GPU communications. Second, the size of GPU memory matters a lot, where some big models may not able to run for a GPU with a small memory. This could be a big problem as it is not a performance issue that you can pay more time to run but could be totally not working (e.g., using a small batch to save memory but the training is not stable). We will discuss the rest components first so all the budget leftover can be used for your GPU, as discussed in the summary.","title":"GPU"},{"location":"hw/#cpu","text":"As the computation load is mostly on the GPU, a cost-effective CPU that can handle a few processes is good enough. Note that most high-end CPUs are designed for doubled or tripled cores/threads, not much for frequency (or speed) on a single process. So an ideal CPU should be on the low-end like almost free so later you can replace it with no regret. My first CPU is just a $50 pentium for a single CPU. But I suggest to use i3 (around $120) to support 2~3 GPUs (I didn't see much difference when compare them with an i5). Plus, you may get a free fan from a low-end CPU.","title":"CPU"},{"location":"hw/#motherboard","text":"A good motherboard is essential for expandability. So make sure the combination of CPU/motherboard and power supply can match each other within 1~2 years of upgrades. As we aim for 2~3 GPUs in future, make sure you have 2~3 PCIe slots. PCIe should be configured at 2 * 8x for two GPUs or 2 * 8x + 4x for 3 GPUs. In most cases, one GPU runs on 8x won't hurt your performance much (compared one one 16x) but allow you to install two GPUs. PCIe 4x may throttle the performance but its OK for my NLP applications. Of course, there's no problem when you just have one GPU running at 16x and almost all motherboard can support that. I assume we may upgrade to 64GB memory in future (16GB per module), so we possibly need a motherboard with 4 memory slots. Open-box/refurbished motherboard may save a lot but still have good enough quality for 1~2 years. I have an open-boxed ASUS prime for 2 years at $80. It still works quite well now. It also comes with a (debug) power button (so I have the chance to not buy a case at all). Note that some sellers like Microcenter may have a combo with CPU to save $30, even including their open-boxed motherboard.","title":"Motherboard"},{"location":"hw/#memory","text":"The good news is that the crazily high memory price is gone. Now you can easily pick a new 16GB memory for $75, which is usually good for 1~2 GPUs (except some poorly writen python project).","title":"Memory"},{"location":"hw/#ssd","text":"For the first storage device, I think no need to consider a hard disk but just go for SSD because many DL models are large and slow to load/save checkpoints. Make sure it's at least $500 GB (about $60) and 1TB could be better. Also, check if you have some external hard disks so to store not-in-use DL projects out there in future.","title":"SSD"},{"location":"hw/#power-supply","text":"Consider to have a power supply to support 2~3 GPUs ahead (250w for a 1080Ti, 260w for a 2080Ti). These add up to at least 900w for 3 GPUs. I have a 850w open-boxed Corsair one with warranty for $80.","title":"Power Supply"},{"location":"hw/#accessories","text":"To be frugal, I won't discuss things like keyboard or mouse and I assume you have at least a normally working one for those and a laptop. So after installing the OS and basic configuration. You can use your laptop to remotely run everything. Also you may consider a $30 case but I totally run my system in the air and my motherboard has a power button so no need to short-circuit the pins to power up and have a configuration that is easy to upgrade.","title":"Accessories"},{"location":"hw/#summary","text":"As a summary, we have a $120 CPU + $80 motherboard + $75 memory + $60 SSD + $80 power supply = $415. If I assume my budget is $1000, then I have $585 for GPU, which is good enough for a 2070 (as recommended by many articles) and close to a 2080. It depends on your budget to try 2080 Ti/Titan RTX.","title":"Summary"},{"location":"llrep/","text":"Lifelong Representation Learning Our research focus is on unsupervised (or self-supervised) domain representation learning, because getting strong supervision from humans is typically not intelligent enough. Even DL has the data-intensive generalization, it still (and may always) suffers from the domain problem in two perspectives: (1) the distribution of data is changed in an end task and certain types of data never appear before; (2) the majority wins the representation where domain-specific representations are squeezed but later challenged by a domain task. Although most NLP tasks are defined on formal writings such as articles from Wikipedia, informal texts are largely ignored in many NLP tasks but are in huge amount. As such, representations learned from formal texts are challenged by domains with informal texts (which may differ in style-of-writing or rich opinions). Consequently, the representation is not general enough. Word Level On the word level, we show that such change of domains makes word embeddings trained from Wikipedia not suitable for reviews. For example, on the word-level, some well-known word embeddings are trained from web pages in the world, where a certain amount of reviews may present. But they are still a small fraction among all web pages and 300 dimension embeddings may not have enough room to save those minor details. We demonstrated that even GloVe is not perfect on review-based tasks. What is even interesting is that the domain problem is word-by-word , not domain-by-domain. For some general stop words, we believe the representation from the natural distribution of web pages win as those words should be used for any domain and GloVe provides such generality that a domain corpus may not give. For domain specific-words, we don't wish distributions from irrelevant domains bias them. For example, we may only wish bright is closely associated with screen or keyboard but not sun in a Laptop domain. Thus, the ideal case is to combine them together and we show a simple way to do that. Context Level Similar things happen to as in contextualized representation learning. Given the complexity of contextualized representation learning, we propose to add more internal stages of training (between pre-training and fine-tuning) for contextualized word representation. BERT Post-Training Via ablation study, we show that a language model ( BERT ) pre-trained on Wikipedia and Bookcorpus is incapable of handling 3 review-based tasks well. We introduce a post-training stage to adapt BERT for a specific domain (the more specific the better). The idea is simple, many training corpora such as the MASK is bright does not contain much learnable knowledge. But if I contraint the domain to laptop , you probably can guess MASK is screen . BERT Pre-tuning The general unsupervised learning (such as BERT) may lead to representations more general to a wide spectrum of tasks but less specific to an end task. To this end we further add a pre-tuning stage for a specific task. This is more important in contextualized representation learning as to whether certain contexts are important or not is very task-specific. We show that less supervised training data for an end task is unable to learn enough task representation and certain methods to bridge the gap is needed.","title":"Lifelong Representation Learning"},{"location":"llrep/#lifelong-representation-learning","text":"Our research focus is on unsupervised (or self-supervised) domain representation learning, because getting strong supervision from humans is typically not intelligent enough. Even DL has the data-intensive generalization, it still (and may always) suffers from the domain problem in two perspectives: (1) the distribution of data is changed in an end task and certain types of data never appear before; (2) the majority wins the representation where domain-specific representations are squeezed but later challenged by a domain task. Although most NLP tasks are defined on formal writings such as articles from Wikipedia, informal texts are largely ignored in many NLP tasks but are in huge amount. As such, representations learned from formal texts are challenged by domains with informal texts (which may differ in style-of-writing or rich opinions). Consequently, the representation is not general enough.","title":"Lifelong Representation Learning"},{"location":"llrep/#word-level","text":"On the word level, we show that such change of domains makes word embeddings trained from Wikipedia not suitable for reviews. For example, on the word-level, some well-known word embeddings are trained from web pages in the world, where a certain amount of reviews may present. But they are still a small fraction among all web pages and 300 dimension embeddings may not have enough room to save those minor details. We demonstrated that even GloVe is not perfect on review-based tasks. What is even interesting is that the domain problem is word-by-word , not domain-by-domain. For some general stop words, we believe the representation from the natural distribution of web pages win as those words should be used for any domain and GloVe provides such generality that a domain corpus may not give. For domain specific-words, we don't wish distributions from irrelevant domains bias them. For example, we may only wish bright is closely associated with screen or keyboard but not sun in a Laptop domain. Thus, the ideal case is to combine them together and we show a simple way to do that.","title":"Word Level"},{"location":"llrep/#context-level","text":"Similar things happen to as in contextualized representation learning. Given the complexity of contextualized representation learning, we propose to add more internal stages of training (between pre-training and fine-tuning) for contextualized word representation.","title":"Context Level"},{"location":"llrep/#bert-post-training","text":"Via ablation study, we show that a language model ( BERT ) pre-trained on Wikipedia and Bookcorpus is incapable of handling 3 review-based tasks well. We introduce a post-training stage to adapt BERT for a specific domain (the more specific the better). The idea is simple, many training corpora such as the MASK is bright does not contain much learnable knowledge. But if I contraint the domain to laptop , you probably can guess MASK is screen .","title":"BERT Post-Training"},{"location":"llrep/#bert-pre-tuning","text":"The general unsupervised learning (such as BERT) may lead to representations more general to a wide spectrum of tasks but less specific to an end task. To this end we further add a pre-tuning stage for a specific task. This is more important in contextualized representation learning as to whether certain contexts are important or not is very task-specific. We show that less supervised training data for an end task is unable to learn enough task representation and certain methods to bridge the gap is needed.","title":"BERT Pre-tuning"},{"location":"overview/","text":"Overview Deep learning (DL) has gained significant improvements over the past a few years, where back-propagation serves as the core driving force to learn features or representations from multiple parameterized layers automatically. This finally bridges the gap between the raw inputs (pixels for CV and sequence of chars for NLP) and the output of an ML task. As such, parameter-intensive DL models can consume much more data than traditional ML models to allow for data-intensive generalization and as a result, better performance. Learning with less human efforts Looking forward, there is no free lunch for an ML model and DL is not perfect. As AI aims to free human from intensive labor work, we humans naturally apply constraints(needs) on an ML model. So neither intensive data annotation nor architecture design for a specific task is desirable. This rule out strongly supervised learning with tens of thousands of examples or architecture rich but parameter fewer models. In the end, we are looking for simple and general architectures with a huge amount of parameters to let unlabeled data to fill in. This leads to unsupervised (or self-supervised as there is no perfect unsupervised) representation learning, where training signals can be discovered from the input itself. Statistical Generalization Even though, the generalization from DL is still biased by the statistics of the intensive data. By statistics, we mean the majority wins in representation learning. But in real-world, the long-tail of many specifics determines the performance. What is even worse is that the trained agent is facing a dynamic world, where some data seldomly or never appear before may need to dominate the distribution later. Two directions we focus on are lifelong representation learning and open-world learning . In contrast, the i.i.d assumption from a ML model leads us a frequently mistake in research. We drop the timestamp TOO MUCH in testing and 99% of existing datasets lost temporal dependency of examples. By temporal dependency, I mean a USB 3.0 in training but a USB 2.0 in testing; or a iPhone Case in training but a iPhone in testing of recommender system. Randomly shuffling the available data (to manually make the testing has similar distribution as training) and spliting 20% for testing are totally wrong. This may explain why a model with good testing performance has poor performance when facing with human evaluation or real-world deployment. Obviously, a model trained from such a time-distorted dataset can let the model learn very easy post-hoc fact and not recover the hidden causal mechanism of data generation in real-world.","title":"Overview"},{"location":"overview/#overview","text":"Deep learning (DL) has gained significant improvements over the past a few years, where back-propagation serves as the core driving force to learn features or representations from multiple parameterized layers automatically. This finally bridges the gap between the raw inputs (pixels for CV and sequence of chars for NLP) and the output of an ML task. As such, parameter-intensive DL models can consume much more data than traditional ML models to allow for data-intensive generalization and as a result, better performance.","title":"Overview"},{"location":"overview/#learning-with-less-human-efforts","text":"Looking forward, there is no free lunch for an ML model and DL is not perfect. As AI aims to free human from intensive labor work, we humans naturally apply constraints(needs) on an ML model. So neither intensive data annotation nor architecture design for a specific task is desirable. This rule out strongly supervised learning with tens of thousands of examples or architecture rich but parameter fewer models. In the end, we are looking for simple and general architectures with a huge amount of parameters to let unlabeled data to fill in. This leads to unsupervised (or self-supervised as there is no perfect unsupervised) representation learning, where training signals can be discovered from the input itself.","title":"Learning with less human efforts"},{"location":"overview/#statistical-generalization","text":"Even though, the generalization from DL is still biased by the statistics of the intensive data. By statistics, we mean the majority wins in representation learning. But in real-world, the long-tail of many specifics determines the performance. What is even worse is that the trained agent is facing a dynamic world, where some data seldomly or never appear before may need to dominate the distribution later. Two directions we focus on are lifelong representation learning and open-world learning . In contrast, the i.i.d assumption from a ML model leads us a frequently mistake in research. We drop the timestamp TOO MUCH in testing and 99% of existing datasets lost temporal dependency of examples. By temporal dependency, I mean a USB 3.0 in training but a USB 2.0 in testing; or a iPhone Case in training but a iPhone in testing of recommender system. Randomly shuffling the available data (to manually make the testing has similar distribution as training) and spliting 20% for testing are totally wrong. This may explain why a model with good testing performance has poor performance when facing with human evaluation or real-world deployment. Obviously, a model trained from such a time-distorted dataset can let the model learn very easy post-hoc fact and not recover the hidden causal mechanism of data generation in real-world.","title":"Statistical Generalization"},{"location":"owl/","text":"Open-world Learning Background One goal of ML is to automatically discover the hidden casual process that explains the results of real-world, such as mimic and guesses the process of human thoughts so to make similar predictions. However, we humans live in a dynamic world and we keep adjusting our mental process to accommodate the evolving world. But in ML, the old distributions on training may not valid when the model is deployed. It doesn't make sense that in 99% cases a model is trained and deployed then never changed later. That is the major reason why people discussing generalization and a good testing score is always just a score but never means good performance in real-world. ML model should adjust their learned process on new distributions and the ability to change the behavior of a deployed model is a key point to be a general model. We roughly term this as an open-world learning problem. Training a model only as a Data Manipulator One observation from humans is that we do not overfit to many details of the input. Humans' generalization comes from the fact that learning is only on abstractive operation level and we perform good separation between data and their operations. For example, we may automatically forget many numbers but remember the math operations or details of many classes (like more than 10 classes) but as long as the data are presented, we can still perform good classification. Sadly, current ML, especially end2end deep learning, wish to learn everything from the data into the model. Inspired by the above discussion, we set our trial on taking a data manipulator as an approach to solving the open-world learning problem. We wish to see that when the data is changed during testing, the data manipulator (as an ML model) can still accommodate the change to a certain degree. Taking aspect extraction as an example, we show that a testing model can still change its performance as more testing data is available. Open-world Classification As a classic task, traditional classification task only focuses on closed-world learning, where the classes are pre-defined in the training data. The extreme case is when a new class comes during testing/prediction, how could that model handle that? Of course, it will assign one old class to an example belonging to a new class, which is obviously a mistake. The first step is we need to reject all new classes to make the results correct. Openset recognition is such a problem in CV and we also make a text-classification paper . This problem can be further decomposed as a combination of anomaly detection and closed-world classification and all unknown new classes should be detected first by the anomaly detection before passing into closed-world classification, which may not be a very novel problem. Going further, we still want to a classifier to support new classes (so to adapt to a new distribution), where you can always expand, for example, the dense layer before the softmax function with a new row of parameters. But this is still not perfect as new classes can still mixed-in with existing. Or say, we need the anomaly detection part to be open-world, too. So the rejection can also be dynamic. Open-world Classification As such, we really want the classifier to support unlimited classes and the set of known classes can be dynamically maintained, including both adding a new class or delete an old one. Any class not in the known set should be rejected. All the problem comes when the model remembered (overfit) a specific set of classes too much. We humans probably cache existing classes into our brain too much for a small set of classes. For a large set, as we cannot remember all classes, we actually do many comparisons: give an example, compare with existing examples in existing classes. If none of them is similar, we say we don't know those classes and take that as a new one. Now another example coming from that new class, if we find they are similar, we can do classification on that new class now. In the end, we probably only learn the comparison part but no specific class or specific set. Our paper aims to train such a comparator to manipulate an arbitrary set of classes.","title":"Open-world Learning"},{"location":"owl/#open-world-learning","text":"","title":"Open-world Learning"},{"location":"owl/#background","text":"One goal of ML is to automatically discover the hidden casual process that explains the results of real-world, such as mimic and guesses the process of human thoughts so to make similar predictions. However, we humans live in a dynamic world and we keep adjusting our mental process to accommodate the evolving world. But in ML, the old distributions on training may not valid when the model is deployed. It doesn't make sense that in 99% cases a model is trained and deployed then never changed later. That is the major reason why people discussing generalization and a good testing score is always just a score but never means good performance in real-world. ML model should adjust their learned process on new distributions and the ability to change the behavior of a deployed model is a key point to be a general model. We roughly term this as an open-world learning problem.","title":"Background"},{"location":"owl/#training-a-model-only-as-a-data-manipulator","text":"One observation from humans is that we do not overfit to many details of the input. Humans' generalization comes from the fact that learning is only on abstractive operation level and we perform good separation between data and their operations. For example, we may automatically forget many numbers but remember the math operations or details of many classes (like more than 10 classes) but as long as the data are presented, we can still perform good classification. Sadly, current ML, especially end2end deep learning, wish to learn everything from the data into the model. Inspired by the above discussion, we set our trial on taking a data manipulator as an approach to solving the open-world learning problem. We wish to see that when the data is changed during testing, the data manipulator (as an ML model) can still accommodate the change to a certain degree. Taking aspect extraction as an example, we show that a testing model can still change its performance as more testing data is available.","title":"Training a model only as a Data Manipulator"},{"location":"owl/#open-world-classification","text":"As a classic task, traditional classification task only focuses on closed-world learning, where the classes are pre-defined in the training data. The extreme case is when a new class comes during testing/prediction, how could that model handle that? Of course, it will assign one old class to an example belonging to a new class, which is obviously a mistake. The first step is we need to reject all new classes to make the results correct. Openset recognition is such a problem in CV and we also make a text-classification paper . This problem can be further decomposed as a combination of anomaly detection and closed-world classification and all unknown new classes should be detected first by the anomaly detection before passing into closed-world classification, which may not be a very novel problem. Going further, we still want to a classifier to support new classes (so to adapt to a new distribution), where you can always expand, for example, the dense layer before the softmax function with a new row of parameters. But this is still not perfect as new classes can still mixed-in with existing. Or say, we need the anomaly detection part to be open-world, too. So the rejection can also be dynamic. Open-world Classification As such, we really want the classifier to support unlimited classes and the set of known classes can be dynamically maintained, including both adding a new class or delete an old one. Any class not in the known set should be rejected. All the problem comes when the model remembered (overfit) a specific set of classes too much. We humans probably cache existing classes into our brain too much for a small set of classes. For a large set, as we cannot remember all classes, we actually do many comparisons: give an example, compare with existing examples in existing classes. If none of them is similar, we say we don't know those classes and take that as a new one. Now another example coming from that new class, if we find they are similar, we can do classification on that new class now. In the end, we probably only learn the comparison part but no specific class or specific set. Our paper aims to train such a comparator to manipulate an arbitrary set of classes.","title":"Open-world Classification"},{"location":"pub/","text":"Publication 2019 Open-world Learning and Application to Product Classification The Web Conference (WWW 2019) Hu Xu , Bing Liu, Lei Shu, P. Yu [ arxiv ], [ code ] BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis (using BERT for review-based tasks) 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2019) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ], [ code ], [ dataset ] Flexibly-Structured Model for Task-Oriented Dialogues SIGDIAL 2019 Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng and Gokhan Tur [paper], [code] Modeling Multi-Action Policy for Task-Oriented Dialogues 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019) Lei Shu, Hu Xu , Bing Liu and Piero Molino Review Conversational Reading Comprehension arXiv 1902.00821 Hu Xu , Bing Liu, Lei Shu and Philip S. Yu [ paper ] 2018 Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018) (This paper won Yelp Dataset Challenge Round 12 Grand Prize Award) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ paper ], [ code ], [ domain embedding ], [ bib ], [ poster ] Lifelong Domain Word Embedding via Meta-Learning International Joint Conference on Artificial Intelligence (IJCAI 2018) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ], [ code ], [ bib ], [ slides ] Dual Attention Network for Product Compatibility and Function Satisfiability Analysis AAAI Conference on Artificial Intelligence (AAAI 2018) (This paper focuses on complementary aspect extraction and polarity classification from question-answering pairs) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ], [ slides ] Incorporating the Structure of the Belief State in End-to-End Task-Oriented Dialogue Systems NeurIPS 2018 Conversational AI Workshop Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng, Gokhan Tur [ paper ] Unseen Class Discovery in Open-world Classification preprint arXiv:1801.05609 Lei Shu, Hu Xu , Bing Liu [ arxiv ] 2017 Product Function Need Recognition via Semi-supervised Attention Network IEEE International Conference on Big Data 2017 (IEEE Bigdata 2017) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ] DOC: Deep Open Classification of Text Documents 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ], [code: EMNLP2017 , www2019 ] Lifelong Learning CRF for Supervised Aspect Extraction the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ] 2016 Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion arXiv preprint arXiv:1612.04499 Hu Xu , Lei Shu, Jingyuan Zhang, Philip S. Yu [ paper ], [ dataset ], [ bib ] CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews (Previous title: Sentence-level Extraction of Complementary Entities using Large Unlabeled Product Reviews) IEEE International Conference on Big Data 2016 (IEEE Bigdata 2016) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ slides ], [ data ], [ bib ] Lifelong-RL: Lifelong Relaxation Labeling for Separating Entities and Aspects in Opinion Targets (Previous title: Separating entities and aspects in opinion targets using lifelong graph labeling) 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016) Lei Shu, Bing Liu, Hu Xu , and Annice Kim [ paper ], [ slides ], [ bib ] 2013 Planning Paths with Fewer Turns on Grid Maps AAAI Sixth Annual Symposium on Combinatorial Search Hu Xu , Lei Shu, May Huang [ paper ], [ dataset ], [ bib ] High-speed and accurate laser scan matching using classified features IEEE International Symposium on Robotic and Sensors Environments (ROSE), 2013 Lei Shu, Hu Xu , May Huang [check IEEE database], [ bib ] 2011 Accuracy analysis of power characterization and modeling Convergence and Hybrid Information Technology Springer Berlin Heidelberg Xiaolan Bai, Hu Xu and May Huang [check Springer Database]","title":"Publication"},{"location":"pub/#publication","text":"","title":"Publication"},{"location":"pub/#2019","text":"Open-world Learning and Application to Product Classification The Web Conference (WWW 2019) Hu Xu , Bing Liu, Lei Shu, P. Yu [ arxiv ], [ code ] BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis (using BERT for review-based tasks) 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2019) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ], [ code ], [ dataset ] Flexibly-Structured Model for Task-Oriented Dialogues SIGDIAL 2019 Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng and Gokhan Tur [paper], [code] Modeling Multi-Action Policy for Task-Oriented Dialogues 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019) Lei Shu, Hu Xu , Bing Liu and Piero Molino Review Conversational Reading Comprehension arXiv 1902.00821 Hu Xu , Bing Liu, Lei Shu and Philip S. Yu [ paper ]","title":"2019"},{"location":"pub/#2018","text":"Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018) (This paper won Yelp Dataset Challenge Round 12 Grand Prize Award) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ paper ], [ code ], [ domain embedding ], [ bib ], [ poster ] Lifelong Domain Word Embedding via Meta-Learning International Joint Conference on Artificial Intelligence (IJCAI 2018) Hu Xu , Bing Liu, Lei Shu, Philip S. Yu [ arxiv ], [ code ], [ bib ], [ slides ] Dual Attention Network for Product Compatibility and Function Satisfiability Analysis AAAI Conference on Artificial Intelligence (AAAI 2018) (This paper focuses on complementary aspect extraction and polarity classification from question-answering pairs) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ], [ slides ] Incorporating the Structure of the Belief State in End-to-End Task-Oriented Dialogue Systems NeurIPS 2018 Conversational AI Workshop Lei Shu, Piero Molino, Mahdi Namazifar, Bing Liu, Hu Xu , Huaixiu Zheng, Gokhan Tur [ paper ] Unseen Class Discovery in Open-world Classification preprint arXiv:1801.05609 Lei Shu, Hu Xu , Bing Liu [ arxiv ]","title":"2018"},{"location":"pub/#2017","text":"Product Function Need Recognition via Semi-supervised Attention Network IEEE International Conference on Big Data 2017 (IEEE Bigdata 2017) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ] DOC: Deep Open Classification of Text Documents 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ], [code: EMNLP2017 , www2019 ] Lifelong Learning CRF for Supervised Aspect Extraction the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017) Lei Shu, Hu Xu , Bing Liu [ paper ], [ bib ]","title":"2017"},{"location":"pub/#2016","text":"Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion arXiv preprint arXiv:1612.04499 Hu Xu , Lei Shu, Jingyuan Zhang, Philip S. Yu [ paper ], [ dataset ], [ bib ] CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews (Previous title: Sentence-level Extraction of Complementary Entities using Large Unlabeled Product Reviews) IEEE International Conference on Big Data 2016 (IEEE Bigdata 2016) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ slides ], [ data ], [ bib ] Lifelong-RL: Lifelong Relaxation Labeling for Separating Entities and Aspects in Opinion Targets (Previous title: Separating entities and aspects in opinion targets using lifelong graph labeling) 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016) Lei Shu, Bing Liu, Hu Xu , and Annice Kim [ paper ], [ slides ], [ bib ]","title":"2016"},{"location":"pub/#2013","text":"Planning Paths with Fewer Turns on Grid Maps AAAI Sixth Annual Symposium on Combinatorial Search Hu Xu , Lei Shu, May Huang [ paper ], [ dataset ], [ bib ] High-speed and accurate laser scan matching using classified features IEEE International Symposium on Robotic and Sensors Environments (ROSE), 2013 Lei Shu, Hu Xu , May Huang [check IEEE database], [ bib ]","title":"2013"},{"location":"pub/#2011","text":"Accuracy analysis of power characterization and modeling Convergence and Hybrid Information Technology Springer Berlin Heidelberg Xiaolan Bai, Hu Xu and May Huang [check Springer Database]","title":"2011"},{"location":"qa/","text":"Question Answering We focus on question answering on opinion texts such as reviews and product QA. Review Reading Comprehension (RRC) check this repository and paper . Review Conversational Reading Comprehension (RCRC) check this repository and paper . Complementary Entity Recognition (CER) We have the following paper for this topic: Dual Attention Network for Product Compatibility and Function Satisfiability Analysis AAAI Conference on Artificial Intelligence (AAAI 2018) (This paper focuses on complementary aspect extraction and polarity classification from question-answering pairs) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ], [ slides ] Product Function Need Recognition via Semi-supervised Attention Network IEEE International Conference on Big Data 2017 (IEEE Bigdata 2017) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ] Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion arXiv preprint arXiv:1612.04499 Hu Xu , Lei Shu, Jingyuan Zhang, Philip S. Yu [ paper ], [ dataset ], [ bib ] CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews (Previous title: Sentence-level Extraction of Complementary Entities using Large Unlabeled Product Reviews) IEEE International Conference on Big Data 2016 (IEEE Bigdata 2016) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ slides ], [ data ], [ bib ]","title":"Question Answering"},{"location":"qa/#question-answering","text":"We focus on question answering on opinion texts such as reviews and product QA.","title":"Question Answering"},{"location":"qa/#review-reading-comprehension-rrc","text":"check this repository and paper .","title":"Review Reading Comprehension (RRC)"},{"location":"qa/#review-conversational-reading-comprehension-rcrc","text":"check this repository and paper .","title":"Review Conversational Reading Comprehension (RCRC)"},{"location":"qa/#complementary-entity-recognition-cer","text":"We have the following paper for this topic: Dual Attention Network for Product Compatibility and Function Satisfiability Analysis AAAI Conference on Artificial Intelligence (AAAI 2018) (This paper focuses on complementary aspect extraction and polarity classification from question-answering pairs) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ], [ slides ] Product Function Need Recognition via Semi-supervised Attention Network IEEE International Conference on Big Data 2017 (IEEE Bigdata 2017) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ dataset ], [ bib ] Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion arXiv preprint arXiv:1612.04499 Hu Xu , Lei Shu, Jingyuan Zhang, Philip S. Yu [ paper ], [ dataset ], [ bib ] CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews (Previous title: Sentence-level Extraction of Complementary Entities using Large Unlabeled Product Reviews) IEEE International Conference on Big Data 2016 (IEEE Bigdata 2016) Hu Xu , Sihong Xie, Lei Shu, Philip S. Yu [ paper ], [ slides ], [ data ], [ bib ]","title":"Complementary Entity Recognition (CER)"},{"location":"service/","text":"Service PC Members: ACL2020, AAAI 2019/2020, IJCAI 2018/2019/2020, EMNLP 2019, NAACL 2019, WWW 2019 External Reviewer, ACL 2019, AAAI 2018, IEEE DSAA 2016 Journal Reviewer: JAIR, TKDD, Natural Language Engineering Award Yelp Dataset Challenge Grand Prize Award AAAI Scholarship Presenter Award, University of Illinois at Chicago Travel Award, IEEE International Conference on Big Data May 4th Scholarship, Peking University","title":"Service and Award"},{"location":"service/#service","text":"PC Members: ACL2020, AAAI 2019/2020, IJCAI 2018/2019/2020, EMNLP 2019, NAACL 2019, WWW 2019 External Reviewer, ACL 2019, AAAI 2018, IEEE DSAA 2016 Journal Reviewer: JAIR, TKDD, Natural Language Engineering","title":"Service"},{"location":"service/#award","text":"Yelp Dataset Challenge Grand Prize Award AAAI Scholarship Presenter Award, University of Illinois at Chicago Travel Award, IEEE International Conference on Big Data May 4th Scholarship, Peking University","title":"Award"},{"location":"talk/","text":"Talk Google AI: Learning for Open-world, Host: Dr. Qi Li, 2019 Amazon Alexa AI: Learning for Open-world, Host: Dr. Young-bum Kim , 2019 AAAI 2018: Dual Attention Network for Product Compatibility and Function Satisfiability Analysis, 2018 Bigdata 2016: CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews, 2016 SoCS 2013: Planning Paths with Fewer Turns on Grid Maps, 2013","title":"Talk"},{"location":"talk/#talk","text":"Google AI: Learning for Open-world, Host: Dr. Qi Li, 2019 Amazon Alexa AI: Learning for Open-world, Host: Dr. Young-bum Kim , 2019 AAAI 2018: Dual Attention Network for Product Compatibility and Function Satisfiability Analysis, 2018 Bigdata 2016: CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews, 2016 SoCS 2013: Planning Paths with Fewer Turns on Grid Maps, 2013","title":"Talk"}]}